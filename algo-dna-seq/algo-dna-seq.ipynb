{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all code from the course Algorithms for DNA Sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bio\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive(p, t):\n",
    "    occurrences = []\n",
    "    alignments = 0\n",
    "    comparisons = 0\n",
    "    for i in range(len(t) - len(p) + 1):  # loop over alignments\n",
    "        alignments += 1\n",
    "        match = True\n",
    "        for j in range(len(p)):  # loop over characters\n",
    "            comparisons += 1\n",
    "            if t[i+j] != p[j]:  # compare characters\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            occurrences.append(i)  # all chars matched; record\n",
    "    return occurrences, alignments, comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boyer_moore(p, p_bm, t):\n",
    "    \"\"\" Do Boyer-Moore matching. p=pattern, t=text,\n",
    "        p_bm=BoyerMoore object for p \"\"\"\n",
    "    i = 0\n",
    "    occurrences = []\n",
    "    while i < len(t) - len(p) + 1:\n",
    "        shift = 1\n",
    "        mismatched = False\n",
    "        for j in range(len(p)-1, -1, -1):\n",
    "            if p[j] != t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched:\n",
    "            occurrences.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse fasta file\n",
    "def readGenome(filename):\n",
    "    genome = ''\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            # ignore header line with genome information\n",
    "            if not line[0] == '>':\n",
    "                genome += line.rstrip()\n",
    "    return genome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for Week 2 Coding Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Class Boyer-Moore\n",
    "# class Boyer_Moore is written by Ben Langmead from George Mason University\n",
    "# class also taken from Coursera course notebook\n",
    "def z_array(s):\n",
    "    \"\"\" Use Z algorithm (Gusfield theorem 1.4.1) to preprocess s \"\"\"\n",
    "    assert len(s) > 1\n",
    "    z = [len(s)] + [0] * (len(s)-1)\n",
    "\n",
    "    # Initial comparison of s[1:] with prefix\n",
    "    for i in range(1, len(s)):\n",
    "        if s[i] == s[i-1]:\n",
    "            z[1] += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    r, l = 0, 0\n",
    "    if z[1] > 0:\n",
    "        r, l = z[1], 1\n",
    "\n",
    "    for k in range(2, len(s)):\n",
    "        assert z[k] == 0\n",
    "        if k > r:\n",
    "            # Case 1\n",
    "            for i in range(k, len(s)):\n",
    "                if s[i] == s[i-k]:\n",
    "                    z[k] += 1\n",
    "                else:\n",
    "                    break\n",
    "            r, l = k + z[k] - 1, k\n",
    "        else:\n",
    "            # Case 2\n",
    "            # Calculate length of beta\n",
    "            nbeta = r - k + 1\n",
    "            zkp = z[k - l]\n",
    "            if nbeta > zkp:\n",
    "                # Case 2a: zkp wins\n",
    "                z[k] = zkp\n",
    "            else:\n",
    "                # Case 2b: Compare characters just past r\n",
    "                nmatch = 0\n",
    "                for i in range(r+1, len(s)):\n",
    "                    if s[i] == s[i - k]:\n",
    "                        nmatch += 1\n",
    "                    else:\n",
    "                        break\n",
    "                l, r = k, r + nmatch\n",
    "                z[k] = r - k + 1\n",
    "    return z\n",
    "\n",
    "\n",
    "def n_array(s):\n",
    "    \"\"\" Compile the N array (Gusfield theorem 2.2.2) from the Z array \"\"\"\n",
    "    return z_array(s[::-1])[::-1]\n",
    "\n",
    "\n",
    "def big_l_prime_array(p, n):\n",
    "    \"\"\" Compile L' array (Gusfield theorem 2.2.2) using p and N array.\n",
    "        L'[i] = largest index j less than n such that N[j] = |P[i:]| \"\"\"\n",
    "    lp = [0] * len(p)\n",
    "    for j in range(len(p)-1):\n",
    "        i = len(p) - n[j]\n",
    "        if i < len(p):\n",
    "            lp[i] = j + 1\n",
    "    return lp\n",
    "\n",
    "\n",
    "def big_l_array(p, lp):\n",
    "    \"\"\" Compile L array (Gusfield theorem 2.2.2) using p and L' array.\n",
    "        L[i] = largest index j less than n such that N[j] >= |P[i:]| \"\"\"\n",
    "    l = [0] * len(p)\n",
    "    l[1] = lp[1]\n",
    "    for i in range(2, len(p)):\n",
    "        l[i] = max(l[i-1], lp[i])\n",
    "    return l\n",
    "\n",
    "\n",
    "def small_l_prime_array(n):\n",
    "    \"\"\" Compile lp' array (Gusfield theorem 2.2.4) using N array. \"\"\"\n",
    "    small_lp = [0] * len(n)\n",
    "    for i in range(len(n)):\n",
    "        if n[i] == i+1:  # prefix matching a suffix\n",
    "            small_lp[len(n)-i-1] = i+1\n",
    "    for i in range(len(n)-2, -1, -1):  # \"smear\" them out to the left\n",
    "        if small_lp[i] == 0:\n",
    "            small_lp[i] = small_lp[i+1]\n",
    "    return small_lp\n",
    "\n",
    "\n",
    "def good_suffix_table(p):\n",
    "    \"\"\" Return tables needed to apply good suffix rule. \"\"\"\n",
    "    n = n_array(p)\n",
    "    lp = big_l_prime_array(p, n)\n",
    "    return lp, big_l_array(p, lp), small_l_prime_array(n)\n",
    "\n",
    "\n",
    "def good_suffix_mismatch(i, big_l_prime, small_l_prime):\n",
    "    \"\"\" Given a mismatch at offset i, and given L/L' and l' arrays,\n",
    "        return amount to shift as determined by good suffix rule. \"\"\"\n",
    "    length = len(big_l_prime)\n",
    "    assert i < length\n",
    "    if i == length - 1:\n",
    "        return 0\n",
    "    i += 1  # i points to leftmost matching position of P\n",
    "    if big_l_prime[i] > 0:\n",
    "        return length - big_l_prime[i]\n",
    "    return length - small_l_prime[i]\n",
    "\n",
    "\n",
    "def good_suffix_match(small_l_prime):\n",
    "    \"\"\" Given a full match of P to T, return amount to shift as\n",
    "        determined by good suffix rule. \"\"\"\n",
    "    return len(small_l_prime) - small_l_prime[1]\n",
    "\n",
    "\n",
    "def dense_bad_char_tab(p, amap):\n",
    "    \"\"\" Given pattern string and list with ordered alphabet characters, create\n",
    "        and return a dense bad character table.  Table is indexed by offset\n",
    "        then by character. \"\"\"\n",
    "    tab = []\n",
    "    nxt = [0] * len(amap)\n",
    "    for i in range(0, len(p)):\n",
    "        c = p[i]\n",
    "        assert c in amap\n",
    "        tab.append(nxt[:])\n",
    "        nxt[amap[c]] = i+1\n",
    "    return tab\n",
    "\n",
    "\n",
    "class BoyerMoore(object):\n",
    "    \"\"\" Encapsulates pattern and associated Boyer-Moore preprocessing. \"\"\"\n",
    "\n",
    "    def __init__(self, p, alphabet='ACGT'):\n",
    "        # Create map from alphabet characters to integers\n",
    "        self.amap = {alphabet[i]: i for i in range(len(alphabet))}\n",
    "        # Make bad character rule table\n",
    "        self.bad_char = dense_bad_char_tab(p, self.amap)\n",
    "        # Create good suffix rule table\n",
    "        _, self.big_l, self.small_l_prime = good_suffix_table(p)\n",
    "\n",
    "    def bad_character_rule(self, i, c):\n",
    "        \"\"\" Return # skips given by bad character rule at offset i \"\"\"\n",
    "        assert c in self.amap\n",
    "        assert i < len(self.bad_char)\n",
    "        ci = self.amap[c]\n",
    "        return i - (self.bad_char[i][ci]-1)\n",
    "\n",
    "    def good_suffix_rule(self, i):\n",
    "        \"\"\" Given a mismatch at offset i, return amount to shift\n",
    "            as determined by (weak) good suffix rule. \"\"\"\n",
    "        length = len(self.big_l)\n",
    "        assert i < length\n",
    "        if i == length - 1:\n",
    "            return 0\n",
    "        i += 1  # i points to leftmost matching position of P\n",
    "        if self.big_l[i] > 0:\n",
    "            return length - self.big_l[i]\n",
    "        return length - self.small_l_prime[i]\n",
    "\n",
    "    def match_skip(self):\n",
    "        \"\"\" Return amount to shift in case where P matches T \"\"\"\n",
    "        return len(self.small_l_prime) - self.small_l_prime[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code implemented for course assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive with counts for assignment\n",
    "def naive_counts(p,t):\n",
    "    \"naive matching algorithm with counts of character comparisons performed and counts of alignments tried\"\n",
    "    char_count = 0\n",
    "    align_count = 0\n",
    "    occurrences = []\n",
    "    for i in range(len(t) - len(p) + 1):\n",
    "        align_count += 1\n",
    "        match = True\n",
    "        for j in range(len(p)):\n",
    "            char_count += 1\n",
    "            if t[i+j] != p[j]:\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            occurrences.append(i)\n",
    "    return occurrences, align_count, char_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BM with counts for assignment\n",
    "def boyer_moore_counts(p, bmp, t):\n",
    "    \"\"\" Do BM matching. p=pattern, t=text,\n",
    "        bmp = boyer moore for p \"\"\"\n",
    "    i = 0\n",
    "    occurrences = []\n",
    "    char_count = 0\n",
    "    align_count = 0\n",
    "    while i < len(t) - len(p) + 1:\n",
    "        align_count += 1\n",
    "        shift = 1\n",
    "        mismatched = False\n",
    "        for j in range(len(p)-1, -1, -1):\n",
    "            char_count += 1\n",
    "            if p[j] != t[i+j]:\n",
    "                skip_bc = bmp.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = bmp.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched:\n",
    "            occurrences.append(i)\n",
    "            skip_gs = bmp.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    return occurrences, align_count, char_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Exact occurrences, number of alignments try, number of charcter comparisons try:\n",
      " 56922 799954 984143\n"
     ]
    }
   ],
   "source": [
    "#running problems from the assignment\n",
    "#problem 1 and 2\n",
    "genome_file = readGenome('chr1.GRCh38.excerpt.fasta')\n",
    "p = 'GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG'\n",
    "t = genome_file\n",
    "naive_counts(p, t)\n",
    "occurrences, num_alignments, num_character_comparisons = naive_counts(p, t)\n",
    "print(\"Naive Exact occurrences, number of alignments try, number of charcter comparisons try:\\n\", occurrences[0], num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoyerMoore occurrences, number of alignments try, number of charcter comparisons try:\n",
      " 56922 127974 165191\n"
     ]
    }
   ],
   "source": [
    "#problem 3\n",
    "genome_file = readGenome('chr1.GRCh38.excerpt.fasta')\n",
    "p = 'GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG'\n",
    "t = genome_file\n",
    "bmp = BoyerMoore(p, alphabet='ACGT')\n",
    "\n",
    "occurrences, num_alignments, num_character_comparisons = boyer_moore_counts(p, bmp, t)\n",
    "print(\"BoyerMoore occurrences, number of alignments try, number of charcter comparisons try:\\n\", occurrences[0], num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code and Class taken from Coursera website\n",
    "import bisect\n",
    "\n",
    "def naive_2mm(p, t):\n",
    "    occurrences = []\n",
    "    for i in range(len(t) - len(p) + 1):  \n",
    "        count_mismatch = 0\n",
    "        for j in range(len(p)):  \n",
    "            if t[i+j] != p[j]:  \n",
    "                count_mismatch += 1\n",
    "        if count_mismatch <= 2:\n",
    "            occurrences.append(i)  \n",
    "    return occurrences\n",
    "\n",
    "\n",
    "def approximate_match(p, t, n):\n",
    "    segment_length = int(round(len(p) / (n + 1)))\n",
    "    all_matches = set()\n",
    "    p_idx = Index(t, segment_length)\n",
    "    idx_hits = 0\n",
    "    for i in range(n + 1):\n",
    "        start = i * segment_length\n",
    "        end = min((i + 1) * segment_length, len(p))\n",
    "        matches = p_idx.query(p[start:end])\n",
    "\n",
    "        \n",
    "        for m in matches:\n",
    "            idx_hits += 1\n",
    "            if m < start or m - start + len(p) > len(t):\n",
    "                continue\n",
    "\n",
    "            mismatches = 0\n",
    "\n",
    "            for j in range(0, start):\n",
    "                if not p[j] == t[m - start + j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            for j in range(end, len(p)):\n",
    "                if not p[j] == t[m - start + j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "\n",
    "            if mismatches <= n:\n",
    "                all_matches.add(m - start)\n",
    "    return list(all_matches), idx_hits\n",
    "\n",
    "\n",
    "def approximate_match_subseq(p, t, n, ival):\n",
    "    segment_length = int(round(len(p) / (n + 1)))\n",
    "    all_matches = set()\n",
    "    p_idx = SubseqIndex(t, segment_length, ival)\n",
    "    idx_hits = 0\n",
    "    for i in range(n + 1):\n",
    "        start = i\n",
    "        matches = p_idx.query(p[start:])\n",
    "\n",
    "        \n",
    "        for m in matches:\n",
    "            idx_hits += 1\n",
    "            if m < start or m - start + len(p) > len(t):\n",
    "                continue\n",
    "\n",
    "            mismatches = 0\n",
    "\n",
    "            for j in range(0, len(p)):\n",
    "                if not p[j] == t[m - start + j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "\n",
    "            if mismatches <= n:\n",
    "                all_matches.add(m - start)\n",
    "    return list(all_matches), idx_hits\n",
    "\n",
    "\n",
    "\n",
    "class Index(object):\n",
    "    \"\"\" Holds a substring index for a text T \"\"\"\n",
    "\n",
    "    def __init__(self, t, k):\n",
    "        \"\"\" Create index from all substrings of t of length k \"\"\"\n",
    "        self.k = k  # k-mer length (k)\n",
    "        self.index = []\n",
    "        for i in range(len(t) - k + 1):  # for each k-mer\n",
    "            self.index.append((t[i:i+k], i))  # add (k-mer, offset) pair\n",
    "        self.index.sort()  # alphabetize by k-mer\n",
    "\n",
    "    def query(self, p):\n",
    "        \"\"\" Return index hits for first k-mer of p \"\"\"\n",
    "        kmer = p[:self.k]  # query with first k-mer\n",
    "        i = bisect.bisect_left(self.index, (kmer, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != kmer:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits\n",
    "\n",
    "\n",
    "class SubseqIndex(object):\n",
    "    \"\"\" Holds a subsequence index for a text T \"\"\"\n",
    "\n",
    "    def __init__(self, t, k, interval):\n",
    "        \"\"\" Create index from all subsequences consisting of k characters\n",
    "            spaced ival positions apart.  E.g., SubseqIndex(\"ATAT\", 2, 2)\n",
    "            extracts (\"AA\", 0) and (\"TT\", 1). \"\"\"\n",
    "        self.k = k  # num characters per subsequence extracted\n",
    "        self.interval = interval  # space between them; 1=adjacent, 2=every other, etc\n",
    "        self.index = []\n",
    "        self.span = 1 + interval * (k - 1)\n",
    "        for i in range(len(t) - self.span + 1):  # for each subseq\n",
    "            self.index.append((t[i:i + self.span:interval], i))  # add (subseq, offset)\n",
    "        self.index.sort()  # alphabetize by subseq\n",
    "\n",
    "    def query(self, p):\n",
    "        \"\"\" Return index hits for first subseq of p \"\"\"\n",
    "        subseq = p[:self.span:self.interval]  # query with first subseq\n",
    "        i = bisect.bisect_left(self.index, (subseq, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != subseq:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#problem 4\n",
    "p = 'GGCGCGGTGGCTCACGCCTGTAAT'\n",
    "len(naive_2mm(p, t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5\n",
    "hit_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6\n",
    "# Question 6\n",
    "approximate_match_subseq(p, t, 2, 3)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 3 Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hamming Distance\n",
    "def hammingDistance(x,y):\n",
    "    \"returns the number of bases that need to be changed for x to match y\"\n",
    "    nmm = 0\n",
    "    for i in range(0, len(x)):\n",
    "        if x[i] != y[1]:\n",
    "            nmm += 1\n",
    "    return nmm\n",
    "\n",
    "#Edit Distance using dynamic programing\n",
    "def editDistance(x, y):\n",
    "    # Create distance matrix\n",
    "    D = []\n",
    "    for i in range(len(x)+1):\n",
    "        D.append([0]*(len(y)+1))\n",
    "    # Initialize first row and column of matrix\n",
    "    for i in range(len(x)+1):\n",
    "        D[i][0] = i\n",
    "    for i in range(len(y)+1):\n",
    "        D[0][i] = i\n",
    "    # Fill in the rest of the matrix\n",
    "    for i in range(1, len(x)+1):\n",
    "        for j in range(1, len(y)+1):\n",
    "            distHor = D[i][j-1] + 1\n",
    "            distVer = D[i-1][j] + 1\n",
    "            if x[i-1] == y[j-1]:\n",
    "                distDiag = D[i-1][j-1]\n",
    "            else:\n",
    "                distDiag = D[i-1][j-1] + 1\n",
    "            D[i][j] = min(distHor, distVer, distDiag)\n",
    "    # Edit distance is the value in the bottom right corner of the matrix\n",
    "    return D[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global alignment\n",
    "alphabet = ['A', 'C', 'G', 'T']\n",
    "penalty = [[0, 4, 2, 4, 8], \\\n",
    "           [4, 0, 4, 2, 8], \\\n",
    "           [2, 4, 0, 4, 8], \\\n",
    "           [4, 2, 4, 0, 8], \\\n",
    "           [8, 8, 8, 8, 8]]\n",
    "def globalAlignment(x, y):\n",
    "    dis = []\n",
    "    for i in range(len(x) +1 ):\n",
    "        dis.append([0]*(len(y) + 1))\n",
    "\n",
    "        for i in range(len(x) + 1):\n",
    "            dis[i][0] = dis[i-1][0] + penalty[alphabet.index(x[i-1])][-1]\n",
    "        for i in range(len(y) + 1):\n",
    "            dis[0][i] = dis[0][-1] + penalty[i-1][alphabet.index(y[i-1])]\n",
    "        for i in range(1, len(x) + 1):\n",
    "            for j in range(1, len(y) + 1):\n",
    "                distHor = dis[i][j-1] + penalty[-1][alphabet.index(y[j-1])]\n",
    "                distVer = dis[i-1][j] + penalty[alphabet.index(x[i-1])][-1]\n",
    "                if x[i-1] == y[j-1]:\n",
    "                    distDiagonal = dis[i-1][j-1]\n",
    "                else:\n",
    "                    distDiagonal = dis[i-1][j-1] + penalty[alphabet.index(x[i-1])][alphabet.index(y[j-1])]\n",
    "                dis[i][j] = min(distHor, distVer, distDiagonal)\n",
    "        return dis[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(a,b, min_length=3):\n",
    "    start = 0 \n",
    "    while True:\n",
    "        start = a.find(b[:min_length], start)\n",
    "        if start == -1:\n",
    "            return 0\n",
    "        if b.startswith(a[start:]):\n",
    "            return len(a)-start\n",
    "        start += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (1, 3), (2, 1), (2, 3), (3, 1), (3, 2)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "list(permutations([1,2,3], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_overlap_map(reads,k):\n",
    "    olapse = {}\n",
    "    for a,b in permutations(reads, 2):\n",
    "        olen = overlap(a,b, min_length=k)\n",
    "        if olen > 0:\n",
    "            olapse[(a,b)] = olen\n",
    "    return olapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Programming homework 3\n",
    "genome_file = readGenome('chr1.GRCh38.excerpt.fasta')\n",
    "p = 'GCTGATCGATCGTACG'\n",
    "t = genome_file\n",
    "\n",
    "def fewest_edits(p, t):\n",
    "    edit_num = len(p)\n",
    "    for i in range(len(t)-len(p) + 1):\n",
    "        seq = t[i:i+len(p)]\n",
    "        if editDistance(p, seq) < edit_num:\n",
    "            edit_num = editDistance(p, seq)\n",
    "        if edit_num == 0:\n",
    "            break\n",
    "    return edit_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def editDistanceDP(A, B):\n",
    "    m, n = len(A), len(B)\n",
    "    dp = [[0 for j in range(n+1)] for i in range(m+1)]\n",
    "    for i in range(m+1): dp[i][0] = i\n",
    "    for j in range(n+1): dp[0][j] = j\n",
    "    for i in range(1, m+1):\n",
    "        for j in range(1, n+1):\n",
    "            dp[i][j] = min(\n",
    "                dp[i-1][j-1] + int(A[i-1] != B[j-1]),\n",
    "                dp[i-1][j] + 1,\n",
    "                dp[i][j-1] + 1,\n",
    "            )\n",
    "    return dp[m][n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFastq(filename):\n",
    "    sequences = []\n",
    "    qualities = []\n",
    "    with open(filename) as fh:\n",
    "        while True:\n",
    "            fh.readline()  # skip name line\n",
    "            seq = fh.readline().rstrip()  # read base sequence\n",
    "            fh.readline()  # skip placeholder line\n",
    "            qual = fh.readline().rstrip() # base quality line\n",
    "            if len(seq) == 0:\n",
    "                break\n",
    "            sequences.append(seq)\n",
    "            qualities.append(qual)\n",
    "    return sequences, qualities\n",
    "\n",
    "\n",
    "def overlap(a, b, min_length=3):\n",
    "    \"\"\" Return length of longest suffix of 'a' matching\n",
    "        a prefix of 'b' that is at least 'min_length'\n",
    "        characters long.  If no such overlap exists,\n",
    "        return 0. \"\"\"\n",
    "    start = 0  # start all the way at the left\n",
    "    while True:\n",
    "        start = a.find(b[:min_length], start)  # look for b's prefix in a\n",
    "        if start == -1:  # no more occurrences to right\n",
    "            return 0\n",
    "        # found occurrence; check for full suffix/prefix match\n",
    "        if b.startswith(a[start:]):\n",
    "            return len(a)-start\n",
    "        start += 1  # move just past previous match\n",
    "\n",
    "\n",
    "def smart_overlap_map(reads, k):\n",
    "    olaps = {}\n",
    "    result = {}\n",
    "    for read in reads:\n",
    "        for i in range(len(read)-k+1):\n",
    "            if read[i:i+k] not in olaps:\n",
    "                olaps[read[i:i+k]] = [read]\n",
    "            else:\n",
    "                olaps[read[i:i+k]].append(read)\n",
    "\n",
    "    count = 0\n",
    "    for read in reads:\n",
    "        read_suffix = read[-k:]\n",
    "        for possible_read in olaps[read_suffix]:\n",
    "            if possible_read != read:\n",
    "                olen = overlap(read, possible_read, k)\n",
    "                if olen > 0:\n",
    "                    count += 1\n",
    "                    result[(read, possible_read)] = olen\n",
    "\n",
    "    return result, count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 4 starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(a, b, min_length=3):\n",
    "    \"\"\" Return length of longest suffix of 'a' matching\n",
    "        a prefix of 'b' that is at least 'min_length'\n",
    "        characters long.  If no such overlap exists,\n",
    "        return 0. \"\"\"\n",
    "    start = 0  # start all the way at the left\n",
    "    while True:\n",
    "        start = a.find(b[:min_length], start)  # look for b's suffx in a\n",
    "        if start == -1:  # no more occurrences to right\n",
    "            return 0\n",
    "        # found occurrence; check for full suffix/prefix match\n",
    "        if b.startswith(a[start:]):\n",
    "            return len(a)-start\n",
    "        start += 1  # move just past previous match\n",
    "\n",
    "import itertools\n",
    "\n",
    "#edited scs function to return list of all SCS\n",
    "def scs(ss):\n",
    "    \"\"\" Returns shortest common superstring of given\n",
    "        strings, which must be the same length \"\"\"\n",
    "    shortest_sup = None\n",
    "    \n",
    "    for ssperm in itertools.permutations(ss):\n",
    "        sup = ssperm[0]  # superstring starts as first string\n",
    "        for i in range(len(ss)-1):\n",
    "            # overlap adjacent strings A and B in the permutation\n",
    "            olen = overlap(ssperm[i], ssperm[i+1], min_length=1)\n",
    "            # add non-overlapping portion of B to superstring\n",
    "            sup += ssperm[i+1][olen:]\n",
    "        if shortest_sup is None or len(sup) < len(shortest_sup):\n",
    "            shortest_sup = sup  # found shorter superstring\n",
    "            \n",
    "    return shortest_sup  # return shortest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ccttggattgc'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scs(['cct', 'ctt', 'tgc', 'gat', 'att', 'tgg'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f764e8fa7848e87676ac2bf516243adad6c5e466b305449bb4397a40ec4a950"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
